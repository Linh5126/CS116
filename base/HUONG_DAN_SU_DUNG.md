# ğŸ HÆ¯á»šNG DáºªN Sá»¬ Dá»¤NG SNAKE AI SYSTEM

## ğŸ“‹ **Má»¤C Lá»¤C**
1. [CÃ i Äáº·t](#cÃ i-Ä‘áº·t)
2. [Cáº¥u TrÃºc Há»‡ Thá»‘ng](#cáº¥u-trÃºc-há»‡-thá»‘ng)
3. [Lá»‡nh Training](#lá»‡nh-training)
4. [Lá»‡nh ChÆ¡i Game](#lá»‡nh-chÆ¡i-game)
5. [Lá»‡nh ÄÃ¡nh GiÃ¡](#lá»‡nh-Ä‘Ã¡nh-giÃ¡)
6. [Quáº£n LÃ½ Model](#quáº£n-lÃ½-model)
7. [Troubleshooting](#troubleshooting)

---

## ğŸ”§ **CÃ€I Äáº¶T**

### **1. CÃ i Ä‘áº·t dependencies:**
```bash
pip install -r requirements.txt
```

### **2. Kiá»ƒm tra cÃ i Ä‘áº·t:**
```bash
python -c "import pygame, torch, numpy; print('âœ… All dependencies installed!')"
```

---

## ğŸ“ **Cáº¤U TRÃšC Há»† THá»NG**

```
base/
â”œâ”€â”€ ğŸ® GAME FILES
â”‚   â”œâ”€â”€ game_level1.py          # Level 1 (6 enemies, dá»…)
â”‚   â”œâ”€â”€ game_level2.py          # Level 2 (12 enemies, khÃ³)
â”‚   â””â”€â”€ game_level3.py          # Level 3 (18 enemies, ráº¥t khÃ³)
â”‚
â”œâ”€â”€ ğŸ§  AI FILES
â”‚   â”œâ”€â”€ advanced_trainer.py     # AI training system
â”‚   â”œâ”€â”€ model.py               # Neural network architecture
â”‚   â”œâ”€â”€ trainer.py             # DQN trainer
â”‚   â””â”€â”€ trainer2.py            # Double DQN trainer
â”‚
â”œâ”€â”€ ğŸ¯ EXECUTION FILES
â”‚   â”œâ”€â”€ train_single.py        # Train má»™t level
â”‚   â”œâ”€â”€ play_game.py          # ChÆ¡i game vá»›i AI
â”‚   â””â”€â”€ play_trained_agent.py # Test AI Ä‘Ã£ train
â”‚
â””â”€â”€ ğŸ“Š DATA FOLDERS
    â”œâ”€â”€ saved_models/         # Models Ä‘Ã£ train
    â”œâ”€â”€ saved_experiences/    # Experience replay data
    â”œâ”€â”€ training_results/     # Káº¿t quáº£ training
    â””â”€â”€ plots/               # Biá»ƒu Ä‘á»“ training
```

---

## ğŸš€ **Lá»†NH TRAINING**

### **1. Train CÆ¡ Báº£n**
```bash
python train_single.py <Level> <Algorithm> <Episodes> <EvalInterval>
```

#### **Tham sá»‘:**
- **Level**: `Level1`, `Level2`, `Level3`
- **Algorithm**: `DQN`, `Double_DQN`
- **Episodes**: Sá»‘ episodes train (VD: 2000, 5000)
- **EvalInterval**: ÄÃ¡nh giÃ¡ má»—i X episodes (VD: 200, 500)

#### **VÃ­ dá»¥:**
```bash
# Train Level1 vá»›i DQN, 2000 episodes, eval má»—i 200 episodes
python train_single.py Level1 DQN 2000 200

# Train Level2 vá»›i Double DQN, 5000 episodes, eval má»—i 500 episodes
python train_single.py Level2 Double_DQN 5000 500

# Train Level3 (khÃ³ nháº¥t), 10000 episodes
python train_single.py Level3 DQN 10000 1000
```

### **2. Train NÃ¢ng Cao**

#### **Continue Training (tiáº¿p tá»¥c tá»« model cÅ©):**
```bash
# Há»‡ thá»‘ng tá»± Ä‘á»™ng load model cÅ© náº¿u cÃ³
python train_single.py Level2 DQN 3000 300
```

#### **Train vá»›i Best Model Saving:**
```bash
# Há»‡ thá»‘ng tá»± Ä‘á»™ng save best model
python train_single.py Level1 DQN 2000 200
# â†’ Táº¡o: DQN_Level1.pth (latest) vÃ  DQN_Level1_BEST.pth (best)
```

---

## ğŸ® **Lá»†NH CHÆ I GAME**

### **1. ChÆ¡i vá»›i AI Ä‘Ã£ train**
```bash
python play_game.py <Level> <Algorithm> <NumGames> <ShowDisplay> [ModelType]
```

#### **Tham sá»‘:**
- **Level**: `Level1`, `Level2`, `Level3`
- **Algorithm**: `DQN`, `Double_DQN`
- **NumGames**: Sá»‘ games chÆ¡i (VD: 1, 5, 10)
- **ShowDisplay**: `True` (hiá»ƒn thá»‹), `False` (khÃ´ng hiá»ƒn thá»‹)
- **ModelType**: `latest` (máº·c Ä‘á»‹nh), `best` (model tá»‘t nháº¥t)

#### **VÃ­ dá»¥:**
```bash
# ChÆ¡i 1 game Level1 vá»›i hiá»ƒn thá»‹ (model latest)
python play_game.py Level1 DQN 1 True

# ChÆ¡i 5 games Level2 khÃ´ng hiá»ƒn thá»‹ (test nhanh)
python play_game.py Level2 DQN 5 False

# ChÆ¡i vá»›i best model
python play_game.py Level1 DQN 3 True best

# Test performance Level3
python play_game.py Level3 Double_DQN 10 False latest
```

### **2. ChÆ¡i Interactive (xem AI chÆ¡i tá»«ng bÆ°á»›c)**
```bash
# ChÆ¡i 1 game vá»›i hiá»ƒn thá»‹ Ä‘á»ƒ xem AI strategy
python play_game.py Level2 DQN 1 True best
```

---

## ğŸ“Š **Lá»†NH ÄÃNH GIÃ**

### **1. ÄÃ¡nh giÃ¡ Performance**
```bash
# Táº¡o script Ä‘Ã¡nh giÃ¡ nhanh
python -c "
from advanced_trainer import GameEvaluator, AdvancedAgent
from game_level2 import Level2AI

agent = AdvancedAgent('DQN')
agent.load_model('saved_models/DQN_Level2.pth')
evaluator = GameEvaluator()
result = evaluator.evaluate_agent(agent, Level2AI, 'Level2', 20)
print(f'Win Rate: {result["win_rate"]:.1%}')
print(f'Avg Score: {result["avg_score"]:.1f}')
"
```

### **2. So sÃ¡nh Models**
```bash
# So sÃ¡nh latest vs best model
python play_game.py Level2 DQN 10 False latest
python play_game.py Level2 DQN 10 False best
```

---

## ğŸ—‚ï¸ **QUáº¢N LÃ MODEL**

### **1. Kiá»ƒm tra Models cÃ³ sáºµn**
```bash
# Windows
dir saved_models\

# Linux/Mac
ls saved_models/
```

### **2. Cáº¥u trÃºc tÃªn file:**
```
saved_models/
â”œâ”€â”€ DQN_Level1.pth           # Latest model Level1
â”œâ”€â”€ DQN_Level1_BEST.pth      # Best model Level1
â”œâ”€â”€ DQN_Level2.pth           # Latest model Level2
â”œâ”€â”€ DQN_Level2_BEST.pth      # Best model Level2
â”œâ”€â”€ Double_DQN_Level1.pth    # Double DQN models
â””â”€â”€ ...
```

### **3. Backup Models**
```bash
# Backup models quan trá»ng
copy saved_models\DQN_Level2_BEST.pth saved_models\DQN_Level2_BACKUP.pth
```

### **4. XÃ³a Models cÅ©**
```bash
# XÃ³a models khÃ´ng cáº§n thiáº¿t (cáº©n tháº­n!)
del saved_models\DQN_Level1.pth
```

---

## ğŸ“ˆ **XEM Káº¾T QUáº¢ TRAINING**

### **1. Xem Plots**
```bash
# Má»Ÿ folder plots Ä‘á»ƒ xem biá»ƒu Ä‘á»“
explorer plots\        # Windows
open plots/           # Mac
nautilus plots/       # Linux
```

### **2. Xem Training Results**
```bash
# Xem JSON results
type training_results\DQN_Level2_results.json    # Windows
cat training_results/DQN_Level2_results.json     # Linux/Mac
```

---

## ğŸ¯ **WORKFLOW KHUYáº¾N NGHá»Š**

### **1. Workflow cho ngÆ°á»i má»›i:**
```bash
# BÆ°á»›c 1: Train Level1 (dá»… nháº¥t)
python train_single.py Level1 DQN 2000 200

# BÆ°á»›c 2: Test model
python play_game.py Level1 DQN 5 True best

# BÆ°á»›c 3: Náº¿u win rate > 20%, chuyá»ƒn Level2
python train_single.py Level2 DQN 3000 300

# BÆ°á»›c 4: Test Level2
python play_game.py Level2 DQN 10 False best
```

### **2. Workflow cho ngÆ°á»i cÃ³ kinh nghiá»‡m:**
```bash
# Train multiple levels song song
python train_single.py Level1 DQN 5000 500 &
python train_single.py Level2 Double_DQN 5000 500 &
python train_single.py Level3 DQN 10000 1000 &
```

### **3. Workflow tá»‘i Æ°u performance:**
```bash
# 1. Train vá»›i episodes cao
python train_single.py Level2 DQN 10000 500

# 2. Test vá»›i sample lá»›n
python play_game.py Level2 DQN 50 False best

# 3. So sÃ¡nh algorithms
python train_single.py Level2 Double_DQN 10000 500
```

---

## ğŸ”§ **TROUBLESHOOTING**

### **âŒ Lá»—i thÆ°á»ng gáº·p:**

#### **1. "Model not found"**
```bash
# Kiá»ƒm tra file cÃ³ tá»“n táº¡i khÃ´ng
ls saved_models/DQN_Level1.pth

# Náº¿u khÃ´ng cÃ³, train láº¡i
python train_single.py Level1 DQN 1000 100
```

#### **2. "CUDA out of memory"**
```bash
# Giáº£m batch size trong advanced_trainer.py
# Hoáº·c dÃ¹ng CPU
export CUDA_VISIBLE_DEVICES=""
```

#### **3. "Pygame error"**
```bash
# CÃ i láº¡i pygame
pip uninstall pygame
pip install pygame
```

#### **4. "Size mismatch error"**
```bash
# Model cÅ© khÃ´ng tÆ°Æ¡ng thÃ­ch, xÃ³a vÃ  train láº¡i
del saved_models\DQN_Level1.pth
python train_single.py Level1 DQN 2000 200
```

### **âš ï¸ LÆ°u Ã½ quan trá»ng:**

#### **1. Training Time:**
- **Level1**: ~30-60 phÃºt (2000 episodes)
- **Level2**: ~1-2 giá» (5000 episodes)  
- **Level3**: ~2-4 giá» (10000 episodes)

#### **2. Memory Usage:**
- **RAM**: ~2-4GB khi training
- **Disk**: ~100MB cho models vÃ  data

#### **3. Performance Expected:**
- **Level1**: Win rate 30-60% sau training
- **Level2**: Win rate 10-30% sau training
- **Level3**: Win rate 5-15% sau training

---

## ğŸ“š **EXAMPLES NÃ‚NG CAO**

### **1. Batch Training Script:**
```bash
# Táº¡o file train_all.bat (Windows)
echo python train_single.py Level1 DQN 3000 300 > train_all.bat
echo python train_single.py Level1 Double_DQN 3000 300 >> train_all.bat
echo python train_single.py Level2 DQN 5000 500 >> train_all.bat
echo python train_single.py Level2 Double_DQN 5000 500 >> train_all.bat

# Cháº¡y
train_all.bat
```

### **2. Performance Testing Script:**
```bash
# Táº¡o file test_all.py
cat > test_all.py << 'EOF'
import subprocess
import sys

levels = ['Level1', 'Level2', 'Level3']
algorithms = ['DQN', 'Double_DQN']

for level in levels:
    for algo in algorithms:
        print(f"\nğŸ§ª Testing {algo} on {level}")
        try:
            result = subprocess.run([
                sys.executable, 'play_game.py', 
                level, algo, '10', 'False', 'best'
            ], capture_output=True, text=True)
            print(result.stdout)
        except Exception as e:
            print(f"âŒ Error: {e}")
EOF

python test_all.py
```

### **3. Model Comparison:**
```bash
# So sÃ¡nh performance cá»§a táº¥t cáº£ models
python -c "
import os
models = [f for f in os.listdir('saved_models') if f.endswith('.pth')]
print('ğŸ“ Available Models:')
for model in sorted(models):
    size = os.path.getsize(f'saved_models/{model}') / 1024 / 1024
    print(f'  {model:<25} ({size:.1f} MB)')
"
```

---

## ğŸ‰ **Káº¾T LUáº¬N**

Há»‡ thá»‘ng Snake AI nÃ y cung cáº¥p:
- âœ… **3 levels** vá»›i Ä‘á»™ khÃ³ tÄƒng dáº§n
- âœ… **2 algorithms** (DQN, Double DQN)
- âœ… **Best model saving** tá»± Ä‘á»™ng
- âœ… **Detailed evaluation** vÃ  visualization
- âœ… **Easy-to-use commands** cho má»i use case

**Happy Training!** ğŸš€ğŸğŸ¤– 